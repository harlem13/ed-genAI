{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: Low-Rank Adaptation (LoRA)\n",
    "* Model: bhadresh-savani/distilbert-bert-base-uncased-emotion\n",
    "* Evaluation approach: trainer.train() & trainer.evaluate()\n",
    "* Fine-tuning dataset: Dair-ai/emotion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f551c63a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/ed/anaconda3/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pyarrow in /Users/ed/anaconda3/lib/python3.11/site-packages (15.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pyarrow) (1.24.3)\n",
      "Requirement already satisfied: accelerate in /Users/ed/anaconda3/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (2.2.0.post100)\n",
      "Requirement already satisfied: huggingface-hub in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ed/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: transformers in /Users/ed/anaconda3/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: peft in /Users/ed/anaconda3/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (2.2.0.post100)\n",
      "Requirement already satisfied: transformers in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (0.28.0)\n",
      "Requirement already satisfied: safetensors in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (0.21.4)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers->peft) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ed/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets --upgrade\n",
    "! pip install --upgrade pyarrow\n",
    "! pip install accelerate -U\n",
    "! pip install transformers --upgrade\n",
    "! pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 16000\n",
      "})\n",
      "{'text': ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy', 'ive been feeling a little burdened lately wasnt sure why that was', 'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny', 'i feel as confused about life as a teenager or as jaded as a year old man', 'i have been with petronas for years i feel that petronas has performed well and made a huge profit', 'i feel romantic too'], 'label': [0, 0, 3, 2, 3, 0, 5, 4, 1, 2]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\", trust_remote_code=True)\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "print(dataset[\"train\"])\n",
    "print(dataset[\"train\"][:10])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28c4a78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=6, bias=True)\n",
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
    "    num_labels=6,\n",
    "    id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"},\n",
    "    label2id={\"sadness\":0, \"joy\":1, \"love\":2, \"anger\":3, \"fear\":4, \"surprise\":5},\n",
    ")\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.save_pretrained(\"initial-model\")\n",
    "print(model.classifier)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019b9f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 16000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101, 1045, 2134, 2102, 2514]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
    "\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"], truncation=True), batched=True\n",
    "    )\n",
    "print(tokenized_dataset[\"train\"])\n",
    "print(tokenized_dataset[\"test\"])\n",
    "tokenized_dataset[\"train\"][0][\"input_ids\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889c3c2b-c732-4162-bbcb-8ef3aba9e014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong'],\n",
       " 'label': [0, 0, 3],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       "  [101,\n",
       "   1045,\n",
       "   2064,\n",
       "   2175,\n",
       "   2013,\n",
       "   3110,\n",
       "   2061,\n",
       "   20625,\n",
       "   2000,\n",
       "   2061,\n",
       "   9636,\n",
       "   17772,\n",
       "   2074,\n",
       "   2013,\n",
       "   2108,\n",
       "   2105,\n",
       "   2619,\n",
       "   2040,\n",
       "   14977,\n",
       "   1998,\n",
       "   2003,\n",
       "   8300,\n",
       "   102],\n",
       "  [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5176b07f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 03:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.192258</td>\n",
       "      <td>0.925500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [584 694 161 272 224  65]\n",
      "True Class Distribution: [581 695 159 275 224  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./project1/data/sentiment_classifier/checkpoint-250 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [584 694 161 272 224  65]\n",
      "True Class Distribution: [581 695 159 275 224  66]\n",
      "{'eval_loss': 0.1922580748796463, 'eval_accuracy': 0.9255, 'eval_runtime': 6.8444, 'eval_samples_per_second': 292.21, 'eval_steps_per_second': 4.675, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = labels\n",
    "    accuracy = (predicted_classes == true_classes).mean()\n",
    "    \n",
    "    # Print class distributions\n",
    "    print(\"Predicted Class Distribution:\", np.bincount(predicted_classes))\n",
    "    print(\"True Class Distribution:\", np.bincount(true_classes))\n",
    "    \n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./project1/data/sentiment_classifier\",\n",
    "        learning_rate=2e-5,\n",
    "        use_cpu=False,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.001,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_results_standard=trainer.evaluate()\n",
    "print(eval_results_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5775fadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "loraConfig=LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.2,\n",
    "    bias=\"none\",\n",
    "    target_modules=['q_lin','k_lin', 'v_lin', 'lin1', 'lin2', 'out_lin' 'pre_classifier']\n",
    ")\n",
    "\n",
    "initial_model=model.from_pretrained(\"initial-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894046c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,185,030 || all params: 68,143,116 || trainable%: 1.7390311297182242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unloading and merging model: 100%|██████████| 132/132 [00:00<00:00, 359.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k_lin', 'lin1', 'lin2', 'out_linpre_classifier', 'q_lin', 'v_lin'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_model #, merge_and_unload\n",
    "\n",
    "lora_model = get_peft_model(initial_model,loraConfig)\n",
    "lora_model.print_trainable_parameters()\n",
    "#Reduce the memory footprint by merging adapter weights with the model\n",
    "lora_model = lora_model.merge_and_unload(initial_model,loraConfig)\n",
    "loraConfig.target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d4c908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 01:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.179532</td>\n",
       "      <td>0.926500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [581 691 167 272 231  58]\n",
      "True Class Distribution: [581 695 159 275 224  66]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.050500446319580075, metrics={'train_runtime': 66.0881, 'train_samples_per_second': 242.101, 'train_steps_per_second': 3.783, 'total_flos': 234152829066240.0, 'train_loss': 0.050500446319580075, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_forPEFT = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./project1/data/sentiment_classifier_wpeft\",\n",
    "        learning_rate=2e-5,\n",
    "        use_cpu=False,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.001,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"].rename_column(\"label\",\"labels\"),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].rename_column(\"label\",\"labels\"),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_forPEFT.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [581 691 167 272 231  58]\n",
      "True Class Distribution: [581 695 159 275 224  66]\n",
      "{'eval_loss': 0.17953208088874817, 'eval_accuracy': 0.9265, 'eval_runtime': 6.7367, 'eval_samples_per_second': 296.879, 'eval_steps_per_second': 4.75, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results_wLoRA=trainer_forPEFT.evaluate()\n",
    "print(eval_results_wLoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/anaconda3/lib/python3.11/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lora_model.add_adapter(loraConfig, adapter_name=\"adapter_1\")\n",
    "lora_model.enable_adapters()\n",
    "trainer_forPEFT.save_model(\"lora-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e70c6-64b7-4517-a40a-738b6bd4bf24",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "863ec66e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validation': Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2000\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "lora_model_ft = AutoPeftModelForSequenceClassification.from_pretrained(\"lora-model\")\n",
    "#config = PeftConfig.from_pretrained(\"lora-model\")\n",
    "\n",
    "tokenized_dataset_validation = {}\n",
    "\n",
    "tokenized_dataset_validation[\"validation\"] = dataset[\"validation\"].map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "print(tokenized_dataset_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5883121d-5343-4f76-bb41-ed030b5f77b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [580 692 166 273 230  59]\n",
      "True Class Distribution: [581 695 159 275 224  66]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.05044174575805664, metrics={'train_runtime': 101.0742, 'train_samples_per_second': 158.3, 'train_steps_per_second': 2.473, 'total_flos': 240587257559040.0, 'train_loss': 0.05044174575805664, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_forPEFT_ft = Trainer(\n",
    "    model=lora_model_ft,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./project1/data1/sentiment_classifier_wpeft_ft\",\n",
    "        #I have tried learning_rate between 1e-2 and 2e-4\n",
    "        learning_rate=2e-5,\n",
    "        use_cpu=False,\n",
    "        #I have tried per device size between 8 and 128. Yet, beyond 64 my device runs out of memory.\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        #I have tried to run 1-5 epochs\n",
    "        num_train_epochs=1,\n",
    "        #I have tried weight_decay between 0.1 and 0.001\n",
    "        weight_decay=0.001,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"].rename_column(\"label\",\"labels\"),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].rename_column(\"label\",\"labels\"),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_forPEFT_ft.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3a8147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [557 702 181 266 215  79]\n",
      "True Class Distribution: [550 704 178 275 212  81]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: [558 701 181 266 213  81]\n",
      "True Class Distribution: [550 704 178 275 212  81]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions_wPEFT = trainer_forPEFT.predict(tokenized_dataset_validation[\"validation\"])\n",
    "predictions_wPEFT_ft = trainer_forPEFT_ft.predict(tokenized_dataset_validation[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866ab28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 7.3266683, -1.3848588, -1.6489316, -1.6579152, -2.133351 ,\n",
      "        -2.2893136],\n",
      "       [ 7.3092737, -1.6362753, -2.1889608, -1.5475152, -1.6482623,\n",
      "        -2.2317388],\n",
      "       [-2.4774506,  4.2734942,  4.0861044, -2.8272586, -3.1093655,\n",
      "        -2.6277878],\n",
      "       ...,\n",
      "       [-1.99391  ,  7.0916996, -1.5699017, -2.1599686, -2.144558 ,\n",
      "        -2.0108826],\n",
      "       [-2.6794627,  5.182468 ,  3.3520355, -2.794747 , -3.0530515,\n",
      "        -2.843311 ],\n",
      "       [-2.0570905,  7.070473 , -1.5376037, -2.5843813, -2.4198775,\n",
      "        -1.3191832]], dtype=float32), label_ids=array([0, 0, 2, ..., 1, 1, 1]), metrics={'test_loss': 0.1562727987766266, 'test_accuracy': 0.9335, 'test_runtime': 8.2835, 'test_samples_per_second': 241.444, 'test_steps_per_second': 3.863})\n",
      "PredictionOutput(predictions=array([[ 7.3414755, -1.5093819, -1.6869037, -1.5502182, -2.162981 ,\n",
      "        -2.2826679],\n",
      "       [ 7.326073 , -1.7544694, -2.225881 , -1.440836 , -1.6786766,\n",
      "        -2.2328193],\n",
      "       [-2.4741662,  4.2375846,  4.061156 , -2.7761214, -3.0596435,\n",
      "        -2.5875757],\n",
      "       ...,\n",
      "       [-1.9850138,  7.031724 , -1.5720617, -2.1085124, -2.0663693,\n",
      "        -1.9568743],\n",
      "       [-2.6615558,  5.1594715,  3.3358955, -2.7440553, -2.9784114,\n",
      "        -2.770063 ],\n",
      "       [-2.0484712,  7.019673 , -1.5450372, -2.5264482, -2.3540528,\n",
      "        -1.2692696]], dtype=float32), label_ids=array([0, 0, 2, ..., 1, 1, 1]), metrics={'test_loss': 0.15545226633548737, 'test_accuracy': 0.9345, 'test_runtime': 8.0846, 'test_samples_per_second': 247.384, 'test_steps_per_second': 3.958})\n"
     ]
    }
   ],
   "source": [
    "print(predictions_wPEFT)\n",
    "print(predictions_wPEFT_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a32e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Standart Pretrained Model :  0.9335  + Test Runtime :  8.2835\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with Standart Pretrained Model : \", predictions_wPEFT.metrics[\"test_accuracy\"], \" + Test Runtime : \", predictions_wPEFT.metrics[\"test_runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5881e9d9-4488-441c-8a9c-994c7eb051d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Fine-Tuned Model :  0.9345  + Test Runtime :  8.0846\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with Fine-Tuned Model : \", predictions_wPEFT_ft.metrics[\"test_accuracy\"], \" + Test Runtime : \", predictions_wPEFT_ft.metrics[\"test_runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "769a091e-2ec8-4dae-a2fb-cf13f7df6795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions wPEFT</th>\n",
       "      <th>predictions wPEFT ft</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>talking to a very good friend who had just had a very bad experience which was changing his whole way of looking at life etc</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>i feel less weird about soliciting guys for them because well i am a guy i guess and i dont feel bad about exploiting them maybe</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>i will choose not to focus on him instead focusing on how i feel i will try not to focus on him and instead of being agitated by him i will choose to let the negative feeling go</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>i just feel gassed and low energy</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>i was feeling pretty strange like dinosaur soldier after i read them because in a weird sort of adult or perhaps college aged way my brain was analyzing the books</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                   text  \\\n",
       "258                                                        talking to a very good friend who had just had a very bad experience which was changing his whole way of looking at life etc   \n",
       "732                                                    i feel less weird about soliciting guys for them because well i am a guy i guess and i dont feel bad about exploiting them maybe   \n",
       "1069  i will choose not to focus on him instead focusing on how i feel i will try not to focus on him and instead of being agitated by him i will choose to let the negative feeling go   \n",
       "1713                                                                                                                                                  i just feel gassed and low energy   \n",
       "1940                 i was feeling pretty strange like dinosaur soldier after i read them because in a weird sort of adult or perhaps college aged way my brain was analyzing the books   \n",
       "\n",
       "      predictions wPEFT  predictions wPEFT ft  labels  \n",
       "258                   1                     3       0  \n",
       "732                   4                     5       5  \n",
       "1069                  3                     4       4  \n",
       "1713                  4                     0       0  \n",
       "1940                  4                     5       4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [item[\"text\"] for item in tokenized_dataset_validation[\"validation\"]],\n",
    "        \"predictions wPEFT\": predictions_wPEFT.predictions.argmax(axis=1),\n",
    "        \"predictions wPEFT ft\": predictions_wPEFT_ft.predictions.argmax(axis=1),\n",
    "        \"labels\": predictions_wPEFT.label_ids,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Filter the DataFrame based on the condition\n",
    "filtered_df = df[df[\"predictions wPEFT\"] != df[\"predictions wPEFT ft\"]]\n",
    "\n",
    "# Show all the cells\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "filtered_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a9f4af0-9869-4e24-81a0-1f8c9a2083ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_success = df[(df[\"predictions wPEFT\"] != df[\"predictions wPEFT ft\"]) & (df[\"predictions wPEFT\"] == df[\"labels\"])][\"predictions wPEFT\"].value_counts()\n",
    "count_success_PEFT = df[(df[\"predictions wPEFT\"] != df[\"predictions wPEFT ft\"]) & (df[\"predictions wPEFT ft\"] == df[\"labels\"])][\"predictions wPEFT ft\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9680a70-27db-491c-a8bd-dd2d05619f92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions wPEFT\n",
      "4    1\n",
      "Name: count, dtype: int64\n",
      "predictions wPEFT ft\n",
      "5    1\n",
      "4    1\n",
      "0    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(count_success)\n",
    "print(count_success_PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a7d44-d1bd-46a0-a8e4-81b5ab69a08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
