{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: Low-Rank Adaptation (LoRA)\n",
    "* Model: bhadresh-savani/bert-base-uncased-emotion\n",
    "* Evaluation approach: trainer.train() & trainer.evaluate()\n",
    "* Fine-tuning dataset: Dair-ai/emotion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f551c63a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/ed/anaconda3/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pyarrow in /Users/ed/anaconda3/lib/python3.11/site-packages (15.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /Users/ed/anaconda3/lib/python3.11/site-packages (from pyarrow) (1.24.3)\n",
      "Requirement already satisfied: accelerate in /Users/ed/anaconda3/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (2.2.0.post100)\n",
      "Requirement already satisfied: huggingface-hub in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ed/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: transformers in /Users/ed/anaconda3/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: peft in /Users/ed/anaconda3/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (2.2.0.post100)\n",
      "Requirement already satisfied: transformers in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (0.28.0)\n",
      "Requirement already satisfied: safetensors in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from peft) (0.21.4)\n",
      "Requirement already satisfied: filelock in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ed/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers->peft) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ed/anaconda3/lib/python3.11/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ed/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ed/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ed/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets --upgrade\n",
    "! pip install --upgrade pyarrow\n",
    "! pip install accelerate -U\n",
    "! pip install transformers --upgrade\n",
    "! pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4935cb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 16000\n",
      "})\n",
      "i didnt feel humiliated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\", trust_remote_code=True)\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "print(dataset[\"train\"])\n",
    "print(dataset[\"train\"][0][\"text\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bhadresh-savani/bert-base-uncased-emotion\",\n",
    "    num_labels=6,\n",
    "    id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"},\n",
    "    label2id={\"sadness\":0, \"joy\":1, \"love\":2, \"anger\":3, \"fear\":4, \"surprise\":5},\n",
    ")\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.save_pretrained(\"initial-model\")\n",
    "model.classifier\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019b9f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 16000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101, 1045, 2134, 2102, 2514]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/bert-base-uncased-emotion\")\n",
    "\n",
    "def preprocess_function(input_data):\n",
    "    return tokenizer(input_data[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(preprocess_function, batched=True)\n",
    "\n",
    "print(tokenized_dataset[\"train\"])\n",
    "print(tokenized_dataset[\"test\"])\n",
    "tokenized_dataset[\"train\"][0][\"input_ids\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5176b07f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 33:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.735300</td>\n",
       "      <td>1.652069</td>\n",
       "      <td>0.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.620600</td>\n",
       "      <td>1.561970</td>\n",
       "      <td>0.347500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./project1/data/sentiment_classifier\",\n",
    "        learning_rate=2e-3,\n",
    "        use_cpu=False,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "eval_results_standard=trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5775fadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "loraConfig=LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=['query','value']\n",
    ")\n",
    "\n",
    "initial_model=model.from_pretrained(\"initial-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894046c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 299,526 || all params: 109,786,380 || trainable%: 0.2728261921014246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unloading and merging model: 100%|██████████| 258/258 [00:00<00:00, 3370.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query', 'value'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_model #, merge_and_unload\n",
    "\n",
    "lora_model = get_peft_model(initial_model,loraConfig)\n",
    "lora_model.print_trainable_parameters()\n",
    "#Reduce the memory footprint by merging adapter weights with the model\n",
    "lora_model = lora_model.merge_and_unload(initial_model,loraConfig)\n",
    "loraConfig.target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d4c908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 1:01:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.601800</td>\n",
       "      <td>1.561532</td>\n",
       "      <td>0.347500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=1.4981998672485353, metrics={'train_runtime': 3686.9506, 'train_samples_per_second': 4.34, 'train_steps_per_second': 1.085, 'total_flos': 629726633071200.0, 'train_loss': 1.4981998672485353, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer_forPEFT = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./project1/data/sentiment_classifier_wpeft\",\n",
    "        learning_rate=2e-3,\n",
    "        use_cpu=False,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"].rename_column(\"label\",\"labels\"),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].rename_column(\"label\",\"labels\"),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_forPEFT.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_wLoRA=trainer_forPEFT.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"lora-model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e70c6-64b7-4517-a40a-738b6bd4bf24",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863ec66e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 2000\n",
       " })}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_validation = {}\n",
    "tokenized_dataset_validation[\"validation\"] = dataset[\"validation\"].map(preprocess_function, batched=True)\n",
    "\n",
    "tokenized_dataset_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3a8147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_dataset_validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m predictions_wPEFT \u001b[38;5;241m=\u001b[39m trainer_forPEFT\u001b[38;5;241m.\u001b[39mpredict(tokenized_dataset_validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy with Standart Pretrained Model : \u001b[39m\u001b[38;5;124m\"\u001b[39m,(predictions \u001b[38;5;241m==\u001b[39m tokenized_dataset_validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     10\u001b[0m df_forPEFT[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions_wPEFT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = trainer.predict(tokenized_dataset_validation[\"validation\"])\n",
    "predictions_wPEFT = trainer_forPEFT.predict(tokenized_dataset_validation[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "866ab28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 6.9475574 , -1.3199435 , -0.97556376, -1.0141709 , -1.562117  ,\n",
       "        -1.7578284 ],\n",
       "       [ 6.927617  , -1.294594  , -1.6009897 , -0.9777841 , -0.9601297 ,\n",
       "        -1.4807993 ],\n",
       "       [-1.7349471 ,  5.123596  ,  3.3889031 , -2.0377204 , -2.675888  ,\n",
       "        -2.2464695 ],\n",
       "       ...,\n",
       "       [-1.2634884 ,  7.087826  , -0.7833872 , -1.7968845 , -2.3344681 ,\n",
       "        -1.3011024 ],\n",
       "       [-2.1280227 ,  5.2574053 ,  2.3886573 , -1.3714836 , -3.0220609 ,\n",
       "        -1.7705295 ],\n",
       "       [-1.7308289 ,  6.9046736 , -1.3093479 , -2.0382638 , -1.6137897 ,\n",
       "        -0.49515936]], dtype=float32), label_ids=array([0, 0, 2, ..., 1, 1, 1]), metrics={'test_loss': 0.15769121050834656, 'test_accuracy': 0.9405, 'test_runtime': 26.0762, 'test_samples_per_second': 76.698, 'test_steps_per_second': 19.175})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9a32e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Standart Pretrained Model :  0.9405  + Test Runtime :  26.0762\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with Standart Pretrained Model : \", predictions.metrics[\"test_accuracy\"], \" + Test Runtime : \", predictions.metrics[\"test_runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5881e9d9-4488-441c-8a9c-994c7eb051d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Fine-Tuned Model :  0.9405  + Test Runtime :  25.6981\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with Fine-Tuned Model : \", predictions_wPEFT.metrics[\"test_accuracy\"], \" + Test Runtime : \", predictions_wPEFT.metrics[\"test_runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "769a091e-2ec8-4dae-a2fb-cf13f7df6795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions w PEFT</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ill snap out of it soon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canvas blank pieces of paper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i start to feel more appreciative of what god has done for me</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i am feeling more confident that we will be able to take care of this baby</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i feel incredibly lucky just to be able to talk to her</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i feel less keen about the army every day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i feel dirty and ashamed for saying that</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         text  \\\n",
       "0       im feeling quite sad and sorry for myself but ill snap out of it soon   \n",
       "1      i feel like i am still looking at a blank canvas blank pieces of paper   \n",
       "2                                              i feel like a faithful servant   \n",
       "3                                           i am just feeling cranky and blue   \n",
       "4                           i can have for a treat or if i am feeling festive   \n",
       "5               i start to feel more appreciative of what god has done for me   \n",
       "6  i am feeling more confident that we will be able to take care of this baby   \n",
       "7                      i feel incredibly lucky just to be able to talk to her   \n",
       "8                                   i feel less keen about the army every day   \n",
       "9                                    i feel dirty and ashamed for saying that   \n",
       "\n",
       "   predictions  predictions w PEFT  labels  \n",
       "0            0                   0       0  \n",
       "1            0                   0       0  \n",
       "2            1                   1       2  \n",
       "3            3                   3       3  \n",
       "4            1                   1       1  \n",
       "5            1                   1       1  \n",
       "6            1                   1       1  \n",
       "7            1                   1       1  \n",
       "8            1                   1       1  \n",
       "9            0                   0       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [item[\"text\"] for item in tokenized_dataset_validation[\"validation\"]],\n",
    "        \"predictions\": predictions.predictions.argmax(axis=1),\n",
    "        \"predictions w PEFT\": predictions_wPEFT.predictions.argmax(axis=1),\n",
    "        \"labels\": predictions.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2e469-b2ef-4cf5-8288-c2f9c12a4a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
